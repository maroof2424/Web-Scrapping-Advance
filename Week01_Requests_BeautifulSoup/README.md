# âœ… **Week 1 â€“ Daily Plan: `requests` + `BeautifulSoup` (Static Scraping)**

### ğŸ—‚ï¸ Folder: `Week01_Requests_BeautifulSoup/`

---

## ğŸ“… **Day 1: Intro to HTTP & Web Scraping**

### ğŸ” Focus:

* What is web scraping?
* How the web works (URLs, HTML, HTTP methods: GET/POST)
* Inspecting web pages using browser dev tools
* Introduction to `requests` and `BeautifulSoup`

### ğŸ§ª Practice:

* Install: `pip install requests beautifulsoup4`
* Make your first `GET` request
* Load and print HTML using BeautifulSoup

### ğŸ“ Files:

```
day01_intro/
â”œâ”€â”€ get_request_demo.py
â””â”€â”€ parse_html_demo.py
```

---

## ğŸ“… **Day 2: HTML Parsing & Data Extraction**

### ğŸ” Focus:

* HTML tags, classes, IDs
* Use `soup.find()`, `soup.find_all()`
* Extract: `.text`, `.get("href")`, `.attrs`

### ğŸ§ª Practice:

* Parse a saved HTML file or use a real webpage
* Extract titles, links, and descriptions from a simple page

### ğŸ“ Files:

```
day02_parsing/
â”œâ”€â”€ extract_links.py
â””â”€â”€ extract_text.py
```

---

## ğŸ“… **Day 3: Scrape Quotes from quotes.toscrape.com**

### ğŸ” Focus:

* Practice full page scraping
* Loop through tags and collect data

### ğŸ§ª Mini Project:

* Scrape quotes, authors, and tags from: [https://quotes.toscrape.com](https://quotes.toscrape.com)

### ğŸ“ Files:

```
day03_quotes/
â”œâ”€â”€ scrape_quotes.py
â””â”€â”€ output_quotes.json
```

---

## ğŸ“… **Day 4: Scrape Books from books.toscrape.com (Part 1)**

### ğŸ” Focus:

* Pagination basics
* Create functions for scraping

### ğŸ§ª Project:

* Scrape book title, price, rating from page 1

### ğŸ“ Files:

```
day04_books/
â”œâ”€â”€ books_page1.py
â””â”€â”€ output_books.csv
```

---

## ğŸ“… **Day 5: Handle Pagination â€“ books.toscrape.com (Part 2)**

### ğŸ” Focus:

* Loop through multiple pages
* Combine results and export to CSV

### ğŸ§ª Project:

* Scrape all book pages (title, price, availability)

### ğŸ“ Files:

```
day05_books_pagination/
â”œâ”€â”€ scrape_all_books.py
â””â”€â”€ all_books.csv
```

---

## ğŸ“… **Day 6: IMDb Top 50 Scraper**

### ğŸ” Focus:

* Nested tag extraction
* Handling attributes, classes

### ğŸ§ª Mini Project:

* Scrape IMDb top 50 movies (title, rating, year)

### ğŸ“ Files:

```
day06_imdb/
â”œâ”€â”€ scrape_imdb_top50.py
â””â”€â”€ imdb_top50.csv
```

---

## ğŸ“… **Day 7: Review + Save to CSV/JSON + Bonus**

### ğŸ” Focus:

* Use `csv` and `json` modules
* Review key concepts
* Add error handling with `try-except`
* Use functions to clean code

### ğŸ§ª Practice:

* Convert previous scrapes to JSON and CSV
* Write reusable scraping functions

### ğŸ“ Files:

```
day07_review/
â”œâ”€â”€ save_csv_json.py
â””â”€â”€ utils.py
```

---

## ğŸ§° Tools You'll Use in Week 1

| Tool            | Use                        |
| --------------- | -------------------------- |
| `requests`      | Send HTTP requests         |
| `BeautifulSoup` | Parse HTML & extract data  |
| `csv` / `json`  | Save structured data       |
| DevTools (F12)  | Inspect web page structure |

---

## Want a Python script to auto-create this Week 1 folder + files?

I can give you a generator script that will:

* Create folders: `day01_intro/`, ..., `day07_review/`
* Add starter `README.md` and empty `.py` files

