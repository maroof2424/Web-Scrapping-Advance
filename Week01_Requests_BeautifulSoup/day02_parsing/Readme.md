## ğŸ“… **Day 2: HTML Parsing & Data Extraction**

---

### ğŸ” **Focus Topics**

* âœ… Understand HTML structure (tags, class, id)
* âœ… Using `soup.find()`, `soup.find_all()`
* âœ… Extracting:

  * `.text`: Get tag text
  * `.get("href")`: Get link URLs
  * `.attrs`: Get all tag attributes

---

### ğŸ§ª **Practice Tasks**

* Use a simple webpage (e.g., `https://example.com`) or saved HTML
* Extract:

  * All links (`<a>`)
  * All headings (`<h1>`, `<h2>`, etc.)
  * Paragraph texts

---

### ğŸ“ **Directory + Files**

```
Week01_Requests_BeautifulSoup/
â””â”€â”€ day02_parsing/
    â”œâ”€â”€ extract_links.py
    â””â”€â”€ extract_text.py
```

---

### ğŸ **File 1: `extract_links.py`**

```python
# extract_links.py

import requests
from bs4 import BeautifulSoup

url = "https://www.example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# Find all <a> tags
links = soup.find_all("a")

print("ğŸ”— All Links on the Page:\n")
for link in links:
    text = link.text.strip()
    href = link.get("href")
    print(f"Text: {text or 'No Text'} | Link: {href}")
```

---

### ğŸ **File 2: `extract_text.py`**

```python
# extract_text.py

import requests
from bs4 import BeautifulSoup

url = "https://www.example.com"
response = requests.get(url)
soup = BeautifulSoup(response.text, "html.parser")

# Extract and print all headings and paragraphs
headings = soup.find_all(["h1", "h2", "h3"])
paragraphs = soup.find_all("p")

print("ğŸ“Œ Headings:")
for h in headings:
    print("-", h.text.strip())

print("\nğŸ“ Paragraphs:")
for p in paragraphs:
    print("-", p.text.strip())
```

---

### ğŸ’¡ Notes:

| Concept        | Example Code         |
| -------------- | -------------------- |
| Find first tag | `soup.find("a")`     |
| Find all tags  | `soup.find_all("a")` |
| Get tag text   | `tag.text.strip()`   |
| Get attribute  | `tag.get("href")`    |
| All attributes | `tag.attrs`          |

---

