## ğŸ“… **Day 1: Intro to HTTP & Web Scraping**

---

### ğŸ” **Focus Topics**

* âœ… What is Web Scraping?
* âœ… How the web works (URLs, HTTP, HTML)
* âœ… HTTP Methods: GET and POST
* âœ… Inspect elements using browser DevTools (F12)
* âœ… Introduction to `requests` and `BeautifulSoup`

---

### ğŸ§ª **Practice Tasks**

1. âœ… Install the required libraries:

   ```bash
   pip install requests beautifulsoup4
   ```
2. âœ… Make your first GET request to a webpage
3. âœ… Load and print HTML using BeautifulSoup

---

### ğŸ“ **Directory + Files**

```
Week01_Requests_BeautifulSoup/
â””â”€â”€ day01_intro/
    â”œâ”€â”€ get_request_demo.py
    â””â”€â”€ parse_html_demo.py
```

---

### ğŸ **File 1: `get_request_demo.py`**

```python
# get_request_demo.py

import requests

url = "https://httpbin.org/get"  # Example URL for testing GET request
response = requests.get(url)

# Status code check
print(f"Status Code: {response.status_code}")

# Raw text content
print("Response Body:")
print(response.text)
```

---

### ğŸ **File 2: `parse_html_demo.py`**

```python
# parse_html_demo.py

import requests
from bs4 import BeautifulSoup

url = "https://www.example.com"
response = requests.get(url)

# Parse with BeautifulSoup
soup = BeautifulSoup(response.text, "html.parser")

# Print entire HTML
print("Full HTML of the page:")
print(soup.prettify())

# Extract page title
title = soup.title.string
print("\nPage Title:", title)
```

---

### ğŸ’¡ Tips for Today:

* Always check the HTTP status code (200 = OK).
* Use `.text` for response content.
* `soup.prettify()` = clean indented HTML.
* `.title.string`, `.find()`, `.find_all()` will be used from Day 2.

